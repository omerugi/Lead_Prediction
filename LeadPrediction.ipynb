{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Lead Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''<<<<Imports>>>>'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.set(font_scale=1.3)\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "import joblib\n",
    "\n",
    "from var import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(IS_TEST_MODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Notebook:\n",
    "\n",
    "#### Plot:\n",
    "*(The plots are active only in test mode)*\n",
    "\n",
    "Functions:\n",
    "- [Single featuer plot](#plt0)\n",
    "- [Multi featuer plot](#plt1)\n",
    "- [Missing featuer print](#plt2)\n",
    "\n",
    "Features plotting: (The plots are after replacing NaN values)\n",
    "- [\"Converted\"](#cell0)\n",
    "- [\"City\"](#cell1)\n",
    "- [\"Country\"](#cell2)\n",
    "- [\"What is your current occupation\"](#cell3)\n",
    "- [\"Receive More Updates About Our Courses\"](#cell4)\n",
    "- [\"Do Not Email\"](#cell5)\n",
    "- [\"Do Not Call\"](#cell6)\n",
    "- [\"All Features Related To \"How did you hear about us\"](#cell7)\n",
    "- [\"Asymmetrique Features\"](#cell8)\n",
    "\n",
    "General:\n",
    "- [\"Missing Data\"](general0)\n",
    "\n",
    "#### Data Engineering:\n",
    "\n",
    "- [Read data](#data0)\n",
    "\n",
    "First step - Replace NaN values and Encode features:\n",
    "- [NaN](#replace1) - Replace NaN with a \"nan_replacment\" var. (can be modifiyed).\n",
    "- [Boolean Encoding](#replace2) - Replace Bool with 0's and 1's.\n",
    "- [Asymmetrique Index Encoding](#replace3) - Replace the low, mid, and high with 1,2,3.\n",
    "- [Lead Quality Encoding](#replace4) - Replace Worst, Low in Relevance, Not Sure, Might be, and High in Relevance with 1-5.\n",
    "- [Step 1 pipline](#replace0) - Will do all the featuer modding of current step in one function to keep the order of the df.\n",
    "\n",
    "Second step - Modify Features:\n",
    "- [Splitting Countries](#mf1) - Because the foucues is on India and also the majorty of smaple are from indea, the values in the featuer are \"India\" and \"Other\".\n",
    "- [Lead Source Typo + Counter Threshold](#mf2) - Fixing typo \"google\" to \"Google\" + Set threshold of 50 for sourses, otherwise \"Other\".\n",
    "- [Replacing \"nan_replacment\" in features](#mf3) - Each featuer that contain \"nan_replacment\" => Replace with featuer's \"Other\" or default value \"Other\".\n",
    "- [Handling \"How did you hear about us\" featuers](#mf4) - Merging features, creating new ones, and mapping from \"How did you hear.. \" to the new features.\n",
    "- [Drop Features](#mf5) - Dropping fetures that are useless.\n",
    "- [Step 2 pipline](#mf6) - Will do all the featuer modding of current step in one function to keep the order of the df.\n",
    "\n",
    "Third step - Features encoding with models:\n",
    "- [OneHot Encoding](#mf7) - Using OneHot Encoding on all the non-numeric features.\n",
    "- [KNNImputer & Median for haddling Asymmetrique Features](#mf8) - Using the the KNN to find the index values of activity and profile, and using the answer to find the score using median. \n",
    "- [Step 3 pipline](#mf9) - Will do all the featuer modding of current step in one function to keep the order of the df.\n",
    "\n",
    "Fourt step - Prediction models:\n",
    "- [Grid score plotting](#mf10) - will plot the best params and score of a grid serch with any model in it.\n",
    "- [Logistic Regression](#mf11) - A logist reg model.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read data: <a id=\"data0\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_data(file_name = data_file_name):\n",
    "    return pd.read_csv(data_file_prefix+file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    raw_df = get_data()\n",
    "    print(raw_df.head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    r_df = get_data()\n",
    "    print(raw_df.columns[raw_df.isin([np.nan]).any()].tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Replace values: "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Replace NaN: <a id=\"replace1\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def replace_nan(df):\n",
    "    '''\n",
    "    The function will replace all NaN / None with the varieble nan_replacment\n",
    "    to fill in all the missing info and avoid issues.\n",
    "    '''\n",
    "    df.apply(lambda x: x if x is not None else nan_replacment)\n",
    "    df = df.fillna(nan_replacment)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Replace Boolean: <a id=\"replace2\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def replace_bool(df):\n",
    "    '''\n",
    "    Replace bool of \"Yes\"/\"No\" with 1/0 accordingly.\n",
    "    '''\n",
    "    return df.replace(\"No\",0).replace(\"Yes\",1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Replace Asymmetrique Index: <a id=\"replace3\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def replace_asy_index(df):\n",
    "    '''\n",
    "    Replace the options in the asy featuers to numeric values,\n",
    "    will make high = 3, mid = 2, and low = 1 to magnitude the higher rank.\n",
    "    '''\n",
    "    return df.replace(\"03.Low\",1).replace(\"02.Medium\",2).replace(\"01.High\",3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Replace Lead Quality: <a id=\"replace4\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def replace_lead_quality(df):\n",
    "    '''\n",
    "    Replace options in lead qulity featuer to numeric values,\n",
    "    scaling from the \"worst\" = 1 to \"High in Relevance\" = 5.\n",
    "    '''\n",
    "    return df.replace(\"Worst\",1).replace(\"Low in Relevance\",2).replace(\"Not Sure\",3).replace(\"Might be\",4).replace(\"High in Relevance\",5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Add \"Converted\": <a id=\"replace5\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def add_converted_label(df):\n",
    "    '''\n",
    "    Will add converted to the data to keep the dataframe shape.\n",
    "    '''\n",
    "    if \"Converted\" not in df.columns:\n",
    "        df[\"Converted\"] = -1\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 1 pipline replace All: <a id=\"replace0\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def step_1_pipline(df):\n",
    "    '''\n",
    "    This it the pipeline to use when predicting on a new sample,\n",
    "    the function will run all the above functions + will reset the indexs\n",
    "    so the dataframe will always be indexed the same, on testing and when running.\n",
    "    '''\n",
    "    return add_converted_label(replace_lead_quality(replace_asy_index(replace_bool(replace_nan(df))))).reset_index(drop=True)\n",
    "\n",
    "def get_step_1_data(file_name = data_step_1):\n",
    "    '''\n",
    "    This function is for testing and to train models fast on knowen data,\n",
    "    it will first try to find a CSV file with the data processed after this steps pipline,\n",
    "    and if it won't find it, will then get the original data run the pipline + save it for later use,\n",
    "    then return the data after this steps pipline.\n",
    "    '''\n",
    "    try: \n",
    "        df = pd.read_csv(data_file_prefix+file_name)\n",
    "    except:\n",
    "        df = step_1_pipline(get_data())\n",
    "        df.to_csv(data_file_prefix+file_name,index=False)\n",
    "    return df\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    r_df = get_step_1_data()\n",
    "    print(r_df.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    raw_df = step_1_pipline(raw_df)\n",
    "    print(raw_df.columns,raw_df.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Ploting:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Single featuer plot: <a id=\"plt0\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_featuer(df, featuer, use_hue = True):\n",
    "    '''\n",
    "    Plot a single featuer's data.\n",
    "    use_hue = will flag if we want to plot the featuer's options.\n",
    "    '''\n",
    "    print(\"Are there any NaN values: \",nan_replacment in df[featuer].unique())\n",
    "    print(\"Number of unique values: \",df[featuer].nunique())\n",
    "    print(\"Unique values count:\\n\",df[featuer].value_counts())\n",
    "    if use_hue:\n",
    "        ax = sns.countplot(x=featuer,hue=featuer, data=df)\n",
    "    else:\n",
    "        ax = sns.countplot(x=featuer, data=df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Multi featuer plot: <a id=\"plt1\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_multiple_feature(df, featuers_lst, use_hue = True):\n",
    "    '''\n",
    "    Plot multiple featuers.\n",
    "    '''\n",
    "    for featuer in featuers_lst:\n",
    "        plot_featuer(df,featuer, use_hue)\n",
    "        plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Featuers with missing data: <a id=\"plt2\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def feature_with_missing_data(df):\n",
    "    '''\n",
    "    Will print out the featuers with missing data.\n",
    "    '''\n",
    "    for feature in raw_df.columns[raw_df.isin([nan_replacment]).any()].tolist():\n",
    "        print(f\"\\\"{feature}\\\" missing data:\")\n",
    "        print(\"Number of unique values: \",df[feature].nunique())\n",
    "        print(f\"Number of {nan_replacment} values: \", (df[feature] == nan_replacment).sum())\n",
    "        print(\"Unique values count:\\n\",df[feature].value_counts())\n",
    "        print(\"-----------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plotting Converted: <a id=\"cell0\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    print(\"Converted:\")\n",
    "    plot_featuer(raw_df, \"Converted\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plotting Cities: <a id=\"cell1\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    print(\"Cities of leads:\")\n",
    "    plot_featuer(raw_df, \"City\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plotting Country: <a id=\"cell2\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    print(\"Country of leads:\")\n",
    "    plot_featuer(raw_df, \"Country\", False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plotting What is your current occupation: <a id=\"cell3\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    print(\"What is your current occupation:\")\n",
    "    plot_featuer(raw_df, \"What is your current occupation\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plotting Receive More Updates About Our Courses: <a id=\"cell4\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    print(\"Receive More Updates About Our Courses:\")\n",
    "    plot_featuer(raw_df, \"Receive More Updates About Our Courses\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plotting Do Not Email <a id=\"cell5\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    print(\"Do Not Email:\")\n",
    "    plot_featuer(raw_df, \"Do Not Email\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plotting Do Not Call <a id=\"cell6\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    print(\"Do Not Call:\")\n",
    "    plot_featuer(raw_df, \"Do Not Call\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plotting All Features Related To \"How did you hear about us\": <a id=\"cell7\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    print(\"How did you hear about X Education:\")\n",
    "    plot_featuer(raw_df, \"How did you hear about X Education\", False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    print(raw_df[['Search', 'Magazine', 'Newspaper Article', 'X Education Forums', 'Newspaper', 'Digital Advertisement', 'Through Recommendations']].mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    plot_multiple_feature(raw_df,['Search', 'Magazine', 'Newspaper Article', 'X Education Forums', 'Newspaper', 'Digital Advertisement', 'Through Recommendations'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " Plotting All Asymmetrique Features: <a id=\"cell8\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    plot_multiple_feature(raw_df,['Asymmetrique Activity Index',\n",
    "       'Asymmetrique Profile Index'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "if IS_TEST_MODE:\n",
    "    plot_multiple_feature(raw_df,['Asymmetrique Activity Score',\n",
    "       'Asymmetrique Profile Score'], False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ploting Missing Data: <a id=\"general0\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    feature_with_missing_data(raw_df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Splitting Countries: <a id=\"mf1\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def split_countries(df):\n",
    "    '''\n",
    "    Will splite the Country into two - india and other (the rest of the countries will all be other).\n",
    "    '''\n",
    "    try:\n",
    "        df.loc[df[\"Country\"] != \"India\", \"Country\"] = \"Other\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Lead Source count and replace values: <a id=\"mf2\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def fix_typo_in_lead_source(df):\n",
    "    '''\n",
    "    Fixing a typo google to match Google.\n",
    "    '''\n",
    "    try:\n",
    "        df.loc[df[\"Lead Source\"] == \"google\", \"Lead Source\"] = \"Google\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return df\n",
    "\n",
    "# Using the first time only to get the featuers that are above the threshold!\n",
    "def replace_values_based_on_threshold_in_lead_source(df, threshold = lead_source_threshold, def_value = def_lead_source_value):\n",
    "    '''\n",
    "    Will make all the options in lead source the with less then the threshold sample equal to \"def_value\".\n",
    "    This function will run only in testing to get the list of options in lead sorce.\n",
    "    '''\n",
    "    for source in df[\"Lead Source\"].unique():\n",
    "        if (df[\"Lead Source\"] == source).sum() < threshold:\n",
    "            df.loc[df[\"Lead Source\"] == source, \"Lead Source\"] = def_value\n",
    "    return df\n",
    "\n",
    "# Use on new samples\n",
    "def check_lead_source(df, ls_opt = lead_source_option, def_value = def_lead_source_value):\n",
    "    '''\n",
    "    If the option is not in the list of options of lead sorce featuer, they will be \"def_value\".\n",
    "    This is set to keep the options in lead sorce always the same.\n",
    "    '''\n",
    "    for source in df[\"Lead Source\"].unique():\n",
    "        if source not in ls_opt: \n",
    "            df.loc[df[\"Lead Source\"] == source, \"Lead Source\"] = def_value\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Replacing \"nan_replacment\" in features: <a id=\"mf3\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def map_nan_replacment_in_features(df,features = features_with_nan_map_to_other,maping = mappping_values):\n",
    "    '''\n",
    "    Replacing missing values in featuers to the featuer's defualt values or other.\n",
    "    '''\n",
    "    for feature in features:\n",
    "        try:\n",
    "            df.loc[df[feature] == nan_replacment, feature] = maping.get(feature,\"Other\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Haddling How did you hear about us featuers: <a id=\"mf4\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def new_featuers_with_zeros(df, features = new_featuers_lst):\n",
    "    '''\n",
    "    Creates new featuer with init = 0.\n",
    "    '''\n",
    "    for feature in features:\n",
    "        if feature not in df.columns:\n",
    "            df[feature] = 0\n",
    "    return df\n",
    "\n",
    "def merge_and_drop_columns(df):\n",
    "    '''\n",
    "    Magazine + Newspaper Article + Newspaper => Newspaper/Magazine. \n",
    "    '''\n",
    "    try:\n",
    "        df.loc[df[\"Magazine\"] == 1,  \"Newspaper/Magazine\"] = 1\n",
    "        df.loc[df[\"Newspaper Article\"] == 1,  \"Newspaper/Magazine\"] = 1\n",
    "        df.loc[df[\"Newspaper\"] == 1,  \"Newspaper/Magazine\"] = 1\n",
    "        df = df.drop([\"Magazine\",\"Newspaper Article\",\"Newspaper\"],axis = 1)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return df\n",
    "\n",
    "def change_digital_advertisement_name(df):\n",
    "    '''\n",
    "    Rename \"Digital Advertisement\" to \"Advertisement\".\n",
    "    '''\n",
    "    try:\n",
    "        df.rename(columns = {\"Digital Advertisement\":\"Advertisement\"}, inplace = True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_feature_to_other_features_and_drop(df, from_to_dict = mapping_featuers_to_new_featuers):\n",
    "    '''\n",
    "    From splitting \"How did you hear about X Education\" to new features.\n",
    "    '''\n",
    "    try:\n",
    "        for option,new_feature in from_to_dict.items():\n",
    "            df.loc[df[\"How did you hear about X Education\"] == option, new_feature] = 1\n",
    "        df = df.drop(\"How did you hear about X Education\", axis = 1)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Drop Features: <a id=\"mf5\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def drop_featuers(df, features = featuers_to_drop):\n",
    "    '''\n",
    "    Drop featuers that seems not relevant.\n",
    "    '''\n",
    "    for feature in features:\n",
    "        try:\n",
    "            df = df.drop(feature, axis = 1)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 2 Data Cleaning Pipline:<a id=\"mf6\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def step_2_pipline(ddf):\n",
    "    '''\n",
    "    This it the pipeline to use when predicting on a new sample,\n",
    "    the function will run all the above functions + test them,\n",
    "    so the dataframe will always be indexed the same, on testing and when running.\n",
    "    '''\n",
    "    df = split_countries(ddf)\n",
    "    test_split_countries(df)\n",
    "    \n",
    "    df = fix_typo_in_lead_source(df)\n",
    "    test_fix_typo_in_lead_source(df)\n",
    "    \n",
    "    df = check_lead_source(df)\n",
    "    test_check_lead_source(df)\n",
    "    \n",
    "    df = map_nan_replacment_in_features(df)\n",
    "    test_map_nan_replacment_in_features(df)\n",
    "    \n",
    "    df = new_featuers_with_zeros(df)\n",
    "    test_new_featuers_with_zeros(df)\n",
    "    \n",
    "    df = merge_and_drop_columns(df)\n",
    "    test_merge_and_drop_columns(df)\n",
    "    \n",
    "    df = change_digital_advertisement_name(df)\n",
    "    test_hange_digital_advertisement_name(df)\n",
    "    \n",
    "    df = split_feature_to_other_features_and_drop(df)\n",
    "    test_split_feature_to_other_features_and_drop(df)\n",
    "    \n",
    "    df = drop_featuers(df)\n",
    "    test_drop_featuers(df)\n",
    "    return df\n",
    "\n",
    "def get_step_2_data(file_name = data_step_2):\n",
    "    '''\n",
    "    This function is for testing and to train models fast on knowen data,\n",
    "    it will first try to find a CSV file with the data processed after this steps pipline,\n",
    "    and if it won't find it, will then try to run the prev pipline + save results for later use,\n",
    "    then return the data after this steps pipline.\n",
    "    '''\n",
    "    try: \n",
    "        df = pd.read_csv(data_file_prefix+file_name)\n",
    "    except:\n",
    "        df = step_2_pipline(get_step_1_data())\n",
    "        df.to_csv(data_file_prefix+file_name,index=False)\n",
    "    return df\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_split_countries(df):\n",
    "    county_lst = df[\"Country\"].unique()\n",
    "    if len(county_lst) == 1:\n",
    "        assert \"India\" in county_lst or \"Other\" in county_lst\n",
    "    else:\n",
    "        assert \"India\" in county_lst and \"Other\" in county_lst\n",
    "    assert df.shape[1] == 36\n",
    "    \n",
    "def test_fix_typo_in_lead_source(df):\n",
    "    ls_lst = df[\"Lead Source\"].unique()\n",
    "    assert \"google\" not in ls_lst\n",
    "    assert df.shape[1] == 36\n",
    "    \n",
    "def test_check_lead_source(df):\n",
    "    for val in df[\"Lead Source\"].unique():\n",
    "        assert val in lead_source_option\n",
    "    assert df.shape[1] == 36\n",
    "    \n",
    "def test_map_nan_replacment_in_features(df):\n",
    "    assert df.shape[1] == 36\n",
    "    for f in df.columns:\n",
    "        assert nan_replacment not in df[f]\n",
    "\n",
    "def test_new_featuers_with_zeros(df):\n",
    "    col = df.columns\n",
    "    for f in new_featuers_lst:\n",
    "        assert f in col\n",
    "        assert df[f].sum() == 0\n",
    "    assert df.shape[1] == 41\n",
    "\n",
    "def test_merge_and_drop_columns(df):\n",
    "    assert df.shape[1] == 38\n",
    "    \n",
    "def test_hange_digital_advertisement_name(df):\n",
    "    assert \"Digital Advertisement\" not in df.columns\n",
    "    assert \"Advertisement\" in df.columns\n",
    "    assert df.shape[1] == 38\n",
    "\n",
    "def test_split_feature_to_other_features_and_drop(df):\n",
    "    assert df.shape[1] == 37\n",
    "    assert \"How did you hear about X Education\" not in df.columns\n",
    "    \n",
    "def test_drop_featuers(df):\n",
    "    assert df.shape[1] == 29"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Models for feature engineering: <a id=\"mf6\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "OneHot Encoding: <a id=\"mf7\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "global onehot_models\n",
    "onehot_models = {}\n",
    "\n",
    "def ohe_path(featuer):\n",
    "    '''\n",
    "    Build the path to the one hot models folder.\n",
    "    '''\n",
    "    return models_path_prefix+ohe_path_prefix+featuer.replace(\" \", \"\").lower()+ohe_path_postfix\n",
    "\n",
    "def init_onehot_models():\n",
    "    '''\n",
    "    Init \"onehot_models\" :\n",
    "    - If there are alrady trained modeles will load them.\n",
    "    - Else will train new models for each featuer + save them + keep in the dict.\n",
    "    '''\n",
    "    df = get_step_2_data()\n",
    "    for feature in one_hot_lst:\n",
    "        path = ohe_path(feature)\n",
    "        try:\n",
    "            with open(path, 'rb') as f:\n",
    "                onehot_models[feature] = pickle.load(f)\n",
    "        except Exception as e:\n",
    "            ohe = OneHotEncoder()\n",
    "            ohe = ohe.fit(df[feature].to_numpy().reshape(-1, 1))\n",
    "            onehot_models[feature] = ohe\n",
    "            with open(path, 'wb') as f:\n",
    "                pickle.dump(ohe, f)\n",
    "\n",
    "def one_hot_featuers(df, features_to_ohe_lst = one_hot_lst):\n",
    "    '''\n",
    "    Will do a one hot encoding on the relevent featuers.\n",
    "    First, tries to get a pre-trained model, if couldn't train a new one.\n",
    "    Second, will transform the featuer into onehot embbedings and keep in the df.\n",
    "    '''\n",
    "    new_df = df.copy()\n",
    "    for feature in features_to_ohe_lst:\n",
    "        if not onehot_models.get(feature,0): init_onehot_models()\n",
    "        ohe = onehot_models.get(feature,0)\n",
    "        try:\n",
    "            dfe = pd.DataFrame(ohe.transform(df[feature].to_numpy().reshape(-1, 1)).toarray())\n",
    "            col_names = { i:f\"{feature} - {col}\" for i,col in enumerate(*ohe.categories_)}\n",
    "            new_df = new_df.drop(feature, axis = 1)\n",
    "            for key,val in col_names.items():\n",
    "                new_df[val] = dfe[key]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return new_df\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "KNNImputer for haddling Asymmetrique Features:<a id=\"mf8\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "global knnimp_model\n",
    "knnimp_model = {}\n",
    "\n",
    "def init_knnimp_model():\n",
    "    '''\n",
    "    Init a \"knnimp_model\":\n",
    "    - If there are alrady trained modeles will load them.\n",
    "    - Else will train new model on the selected featuers  + save + keep in the dict.    \n",
    "    '''\n",
    "    try:\n",
    "        with open(models_path_prefix+imputer_model_path, 'rb') as f:\n",
    "                knnimp_model[\"knn_imp\"] = pickle.load(f)\n",
    "    except:\n",
    "        x,img_df = df_for_knnimp(one_hot_featuers(get_step_2_data()))\n",
    "        knnimp_model[\"knn_imp\"] = KNNImputer(missing_values=np.nan,n_neighbors=2)\n",
    "        knnimp_model[\"knn_imp\"].fit(x)\n",
    "        with open(models_path_prefix+imputer_model_path, 'wb') as f:\n",
    "            pickle.dump(knnimp_model[\"knn_imp\"], f)\n",
    "\n",
    "def get_or_init_knnimp(x):\n",
    "    '''\n",
    "    Will return a pre trained KNNImputer model, and if it won't find, train and save a new one.\n",
    "    '''\n",
    "    if knnimp_model.get(\"knn_imp\",0): return knnimp_model.get(\"knn_imp\")\n",
    "    init_knnimp_model()\n",
    "    return knnimp_model.get(\"knn_imp\")\n",
    "\n",
    "def df_for_knnimp(df):\n",
    "    '''\n",
    "    Get only the relevent samples from the df,\n",
    "    meaning the samples with data in the featuers we wish to fill in.\n",
    "    '''\n",
    "    imp_df = df.copy()\n",
    "    imp_df.loc[imp_df[\"Asymmetrique Activity Index\"] == nan_replacment, \"Asymmetrique Activity Index\"] = np.nan\n",
    "    imp_df.loc[imp_df[\"Asymmetrique Profile Index\"] == nan_replacment, \"Asymmetrique Profile Index\"] = np.nan\n",
    "    imp_df = imp_df.drop(\"Asymmetrique Activity Score\", axis = 1).drop(\"Asymmetrique Profile Score\", axis = 1).drop(\"Converted\", axis = 1)\n",
    "    x = imp_df[(imp_df[\"Asymmetrique Activity Index\"] != np.nan) | (imp_df[\"Asymmetrique Profile Index\"] != np.nan)]\n",
    "    return x,imp_df\n",
    "\n",
    "def data_imputer_on_asymmetrique_features(df):\n",
    "    '''\n",
    "    Use KNNImputer to fill in missing data in featuers + based on the models prediction will fill\n",
    "    in related featuers with the midian of the samples with the same predicted results.\n",
    "    '''\n",
    "    x,imp_df = df_for_knnimp(df)\n",
    "    col_imp_df = imp_df.columns\n",
    "    model = get_or_init_knnimp(x)\n",
    "    imp_df = pd.DataFrame(model.transform(imp_df)).round(0)\n",
    "    col_names = { i:col for i,col in enumerate(col_imp_df)}\n",
    "    imp_df.rename(columns=col_names, inplace= True)\n",
    "    imp_df[\"Asymmetrique Activity Score\"]=df[\"Asymmetrique Activity Score\"]\n",
    "    imp_df[\"Asymmetrique Profile Score\"]=df[\"Asymmetrique Profile Score\"]\n",
    "    for ac_index in imp_df[\"Asymmetrique Activity Index\"].unique():\n",
    "        imp_df.loc[(imp_df[\"Asymmetrique Activity Index\"] == ac_index) & (imp_df[\"Asymmetrique Activity Score\"] == nan_replacment) , \"Asymmetrique Activity Score\"] = asymmetrique_activity_median.get(ac_index,0)\n",
    "    for ac_index in imp_df[\"Asymmetrique Profile Index\"].unique():\n",
    "        imp_df.loc[(imp_df[\"Asymmetrique Profile Index\"] == ac_index) & (imp_df[\"Asymmetrique Profile Score\"] == nan_replacment), \"Asymmetrique Profile Score\"] = asymmetrique_profile_median.get(ac_index,0)\n",
    "    imp_df[\"Converted\"]=df[\"Converted\"]\n",
    "    return imp_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Step 3 pipline encoding featuers with models: <a id=\"mf9\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def step_3_pipline(ddf):\n",
    "    '''\n",
    "    This it the pipeline to use when predicting on a new sample,\n",
    "    the function will run all the above functions,\n",
    "    so the dataframe will always be indexed the same, on testing and when running.\n",
    "    '''\n",
    "    df = one_hot_featuers(ddf)\n",
    "    test_hot_featuers(df)\n",
    "    df = data_imputer_on_asymmetrique_features(df)\n",
    "    return df\n",
    "\n",
    "def get_step_3_data(file_name = data_step_3):\n",
    "    '''\n",
    "    This function is for testing and to train models fast on knowen data,\n",
    "    it will first try to find a CSV file with the data processed after this steps pipline,\n",
    "    and if it won't find it, will then try to run the prev pipline + save results for later use,\n",
    "    then return the data after this steps pipline.\n",
    "    '''\n",
    "    try: \n",
    "        df = pd.read_csv(data_file_prefix+file_name)\n",
    "    except:\n",
    "        df = step_3_pipline(get_step_2_data())\n",
    "        df.to_csv(data_file_prefix+file_name,index=False)\n",
    "    return df   "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def test_hot_featuers(df):\n",
    "    assert df.shape[1] == 86\n",
    "    test_col = one_hot_featuers(get_step_2_data()).columns\n",
    "    for col in test_col:\n",
    "        assert col in df.columns\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Models for predictions: "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "global pred_models\n",
    "pred_models = {}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plotting Scores: <a id=\"mf10\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def print_grid_score(grid,x_test,y_test):\n",
    "    '''\n",
    "    Will print the best parms and the score of the model in the grid.\n",
    "    '''\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(\" %0.3f\" %grid.best_score_ , grid.best_params_, \"\\n\")\n",
    "    y_true, y_pred = y_test, grid.predict(x_test)\n",
    "    print(classification_report(y_true, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Logistic regression : <a id=\"mf11\"></a>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def init_lr_model():\n",
    "    '''\n",
    "    Init a logistic reg model into \"pred_models\":\n",
    "    - If there are alrady trained modeles will load them.\n",
    "    - Else will train new model  + save + keep in the dict.    \n",
    "    '''\n",
    "    try:\n",
    "        pred_models[\"lr\"] = joblib.load(models_path_prefix+lr_model_path)\n",
    "    except:\n",
    "        df = get_step_3_data()\n",
    "        x,y = df.drop(\"Converted\", axis = 1),df[\"Converted\"]\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.33, random_state=0)\n",
    "        lr_grid = train_lr_model(x_train,y_train)\n",
    "        pred_models[\"lr\"] = lr_grid\n",
    "        joblib.dump(pred_models[\"lr\"], models_path_prefix+lr_model_path)\n",
    "        if IS_TEST_MODE: print_grid_score(pred_models[\"lr\"],x_test,y_test)\n",
    "\n",
    "def train_lr_model(x_train,y_train):\n",
    "    '''\n",
    "    Train the lr model with grid serch to find the best params.\n",
    "    '''\n",
    "    log_parm={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "    logreg=LogisticRegression(solver='liblinear')\n",
    "    grid = GridSearchCV(logreg,log_parm,cv=5, scoring='roc_auc',  verbose=2, n_jobs = -1)\n",
    "    grid.fit(x_train,y_train)\n",
    "    return grid\n",
    "\n",
    "def test_lr_model(x_test,y_test):\n",
    "    '''\n",
    "    Test the models results\n",
    "    '''\n",
    "    if not pred_models.get(\"lr\",0): init_lr_model()\n",
    "    print_grid_score(pred_models[\"lr\"],x_test,y_test)\n",
    "    return pred_models[\"lr\"].predict_proba(x_test)\n",
    "\n",
    "def pred_prob_lr_model(df):\n",
    "    '''\n",
    "    Return a prediction as probability on the samples in df.\n",
    "    '''\n",
    "    if not pred_models.get(\"lr\",0): init_lr_model()\n",
    "    x,y = df.drop(\"Converted\", axis = 1),df[\"Converted\"]\n",
    "    return pred_models[\"lr\"].predict_proba(x)\n",
    "\n",
    "def pred_lr_model(df):\n",
    "    '''\n",
    "    Return a prediction label on the samples in df.\n",
    "    '''\n",
    "    if not pred_models.get(\"lr\",0): init_lr_model()\n",
    "    x,y = df.drop(\"Converted\", axis = 1),df[\"Converted\"]\n",
    "    return pred_models[\"lr\"].predict(x)\n",
    "\n",
    "def will_convert_prod_lr_model(df):\n",
    "    '''\n",
    "    Return a prediction as natural number probability if the samples in df will convert.\n",
    "    '''\n",
    "    prob = pred_prob_lr_model(df)\n",
    "    return [int(lst[1]*100) for i,lst in enumerate(prob)]\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    n = get_step_3_data().head(1)\n",
    "    print(will_convert_prod_lr_model(n))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    dfb = step_3_pipline(step_2_pipline(step_1_pipline(get_data())))\n",
    "    x,y = dfb.drop(\"Converted\", axis = 1),dfb[\"Converted\"]\n",
    "    print(pd.DataFrame({\"Pred\":will_convert_prod_lr_model(dfb)})[\"Pred\"].value_counts())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    init_lr_model()\n",
    "    dfc = get_step_3_data()\n",
    "    x,y = dfc.drop(\"Converted\", axis = 1),dfc[\"Converted\"]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.33, random_state=0)\n",
    "    y_pred = test_lr_model(x_test,y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    n = step_1_pipline(get_data().head(1))\n",
    "    print(n.shape)\n",
    "    x = get_step_1_data()\n",
    "    print(x.shape)\n",
    "    n = step_2_pipline(n)\n",
    "    print(n.shape)\n",
    "    x = get_step_2_data()\n",
    "    print(x.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    n = one_hot_featuers(n)\n",
    "    print(n.shape)\n",
    "    x = get_step_3_data()\n",
    "    print(x.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    df = step_3_pipline(step_2_pipline(step_1_pipline(get_data())))\n",
    "    x = get_step_3_data()\n",
    "    for col in df.columns:\n",
    "        for f in df[col].unique():\n",
    "            assert (x[col] == f).count() == (df[col] == f).count()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    n = data_imputer_on_asymmetrique_features(n)\n",
    "    print(n.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    x = step_3_pipline(step_2_pipline(step_1_pipline(get_data().head(1))))\n",
    "    print(x[\"Asymmetrique Activity Index\"].value_counts(dropna = False))\n",
    "    print(x[\"Asymmetrique Activity Score\"].value_counts(dropna = False))\n",
    "    print(x[\"Asymmetrique Profile Index\"].value_counts(dropna = False))\n",
    "    print(x[\"Asymmetrique Profile Score\"].value_counts(dropna = False))\n",
    "    #     for f in x.columns:\n",
    "#         print( x[f].value_counts(dropna = False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    country_df = split_countries(raw_df)\n",
    "    print(country_df[\"Country\"].value_counts(dropna = False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    ls_df = replace_values_based_on_threshold_in_lead_source(fix_typo_in_lead_source(country_df))\n",
    "    print(\"Unique values count:\\n\",raw_df[\"Lead Source\"].value_counts(dropna = False))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    features = [\"How did you hear about X Education\", \"What matters most to you in choosing a course\", \"Lead Profile\", \"City\",\"TotalVisits\",\"Page Views Per Visit\"]\n",
    "    mapping = {\"Lead Profile\":\"Other Leads\", \"City\":\"Other Cities\", \"TotalVisits\": int(ls_df.loc[ls_df[\"TotalVisits\"]!= nan_replacment, \"TotalVisits\"].mean()), \"Page Views Per Visit\": int(ls_df.loc[ls_df[\"Page Views Per Visit\"]!= nan_replacment, \"Page Views Per Visit\"].mean() )}\n",
    "    print(mapping)\n",
    "    map_df = map_nan_replacment_in_features(ls_df,features,mapping)\n",
    "    for f in features:\n",
    "        try:\n",
    "            print(\"Unique values count:\\n\",map_df[f].value_counts(dropna = False))\n",
    "            print(\"-----------------------------------------------\")\n",
    "        except:\n",
    "            pass"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    newf_df = new_featuers_with_zeros(map_df, ['Other','Multiple Sources',\"Social Media\",\"Direct Advertisement\",\"Newspaper/Magazine\"])\n",
    "    print(newf_df.loc[:,['Other','Multiple Sources',\"Social Media\",\"Direct Advertisement\",\"Newspaper/Magazine\"]].head(5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    merge_df = merge_and_drop_columns(newf_df)\n",
    "    merge_df = change_digital_advertisement_name(merge_df)\n",
    "    merge_df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    feature_split = {\n",
    "        \"Online Search\": \"Search\",\n",
    "        \"Word Of Mouth\" : \"Through Recommendations\",\n",
    "        \"Student of SomeSchool\" : \"Through Recommendations\",\n",
    "        \"Other\": \"Other\",\n",
    "        \"Multiple Sources\": \"Multiple Sources\",\n",
    "        \"Advertisements\" : \"Advertisement\",\n",
    "        \"Social Media\" : \"Social Media\",\n",
    "        \"SMS\" : \"Direct Advertisement\",\n",
    "        \"Email\" : \"Direct Advertisement\"\n",
    "    }\n",
    "    split_df=split_feature_to_other_features_and_drop(merge_df,feature_split)\n",
    "    print(split_df.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    for feature in split_df.columns:\n",
    "        unique = split_df[feature].unique()\n",
    "        print(feature,\": \\t\",nan_replacment in unique, np.nan in unique)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    print(split_df[split_df.isnull().any(axis=1)])\n",
    "    drop_df = drop_featuers(split_df, [\"Receive More Updates About Our Courses\",\n",
    "                                    \"Lead Number\",\n",
    "                                    \"City\",\n",
    "                                    \"Last Activity\",\n",
    "                                    \"Tags\",\n",
    "                                    \"Update me on Supply Chain Content\",\n",
    "                                    \"Get updates on DM Content\",\n",
    "                                    \"I agree to pay the amount through cheque\"])\n",
    "    print(drop_df.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    print(drop_df.shape)\n",
    "    dddf = step_2_pipline(step_1_pipline(get_data()))\n",
    "    print(dddf.shape)\n",
    "    df_ohe = one_hot_featuers(drop_df)\n",
    "    print(df_ohe.shape)\n",
    "    print(one_hot_featuers(dddf).shape)\n",
    "    print(df_ohe[df_ohe.isnull().any(axis=1)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    imp_df = data_imputer_on_asymmetrique_features(df_ohe)\n",
    "    print(imp_df[\"Asymmetrique Activity Index\"].value_counts(dropna = False))\n",
    "    print(imp_df[\"Asymmetrique Activity Score\"].value_counts(dropna = False))\n",
    "    print(imp_df[\"Asymmetrique Profile Index\"].value_counts(dropna = False))\n",
    "    print(imp_df[\"Asymmetrique Profile Score\"].value_counts(dropna = False))\n",
    "    print(imp_df.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if IS_TEST_MODE:\n",
    "    for ac_index in imp_df[\"Asymmetrique Activity Index\"].unique():\n",
    "         print(ac_index,\" : \",df_ohe.loc[(imp_df[\"Asymmetrique Activity Index\"] == ac_index) & (df_ohe[\"Asymmetrique Activity Score\"] != nan_replacment)][\"Asymmetrique Activity Score\"].median())\n",
    "    print(\"---------\")\n",
    "    for ac_index in imp_df[\"Asymmetrique Profile Index\"].unique():\n",
    "         print(ac_index,\" : \",df_ohe.loc[(imp_df[\"Asymmetrique Profile Index\"] == ac_index) & (df_ohe[\"Asymmetrique Profile Score\"] != nan_replacment)][\"Asymmetrique Profile Score\"].median())    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Lead Number, Lead Origin, Lead Source, Do Not Email, Do Not Call, Converted, TotalVisits, Total Time Spent on Website, Page Views Per Visit, Last Activity, Country, Specialization, What is your current occupation, What matters most to you in choosing a course, Search, X Education Forums, Advertisement, Through Recommendations, Receive More Updates About Our Courses, Tags, Lead Quality, Update me on Supply Chain Content, Get updates on DM Content, Lead Profile, City, Asymmetrique Activity Index, Asymmetrique Profile Index, Asymmetrique Activity Score, Asymmetrique Profile Score, I agree to pay the amount through cheque, A free copy of Mastering The Interview, Last Notable Activity, Other, Multiple Sources, Social Media, Direct Advertisement, Newspaper/Magazine]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 37 columns]\n",
      "Index(['Lead Origin', 'Lead Source', 'Do Not Email', 'Do Not Call',\n",
      "       'Converted', 'TotalVisits', 'Total Time Spent on Website',\n",
      "       'Page Views Per Visit', 'Country', 'Specialization',\n",
      "       'What is your current occupation',\n",
      "       'What matters most to you in choosing a course', 'Search',\n",
      "       'X Education Forums', 'Advertisement', 'Through Recommendations',\n",
      "       'Lead Quality', 'Lead Profile', 'Asymmetrique Activity Index',\n",
      "       'Asymmetrique Profile Index', 'Asymmetrique Activity Score',\n",
      "       'Asymmetrique Profile Score', 'A free copy of Mastering The Interview',\n",
      "       'Last Notable Activity', 'Other', 'Multiple Sources', 'Social Media',\n",
      "       'Direct Advertisement', 'Newspaper/Magazine'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "if IS_TEST_MODE:\n",
    "    print(split_df[split_df.isnull().any(axis=1)])\n",
    "    drop_df = drop_featuers(split_df, [\"Receive More Updates About Our Courses\",\n",
    "                                    \"Lead Number\",\n",
    "                                    \"City\",\n",
    "                                    \"Last Activity\",\n",
    "                                    \"Tags\",\n",
    "                                    \"Update me on Supply Chain Content\",\n",
    "                                    \"Get updates on DM Content\",\n",
    "                                    \"I agree to pay the amount through cheque\"])\n",
    "    print(drop_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9240, 29)\n",
      "(9240, 29)\n",
      "(9240, 86)\n",
      "(9240, 86)\n",
      "Empty DataFrame\n",
      "Columns: [Do Not Email, Do Not Call, Converted, TotalVisits, Total Time Spent on Website, Page Views Per Visit, Search, X Education Forums, Advertisement, Through Recommendations, Lead Quality, Asymmetrique Activity Index, Asymmetrique Profile Index, Asymmetrique Activity Score, Asymmetrique Profile Score, A free copy of Mastering The Interview, Other, Multiple Sources, Social Media, Direct Advertisement, Newspaper/Magazine, Lead Origin - API, Lead Origin - Landing Page Submission, Lead Origin - Lead Add Form, Lead Origin - Lead Import, Lead Origin - Quick Add Form, Lead Source - Direct Traffic, Lead Source - Facebook, Lead Source - Google, Lead Source - Olark Chat, Lead Source - Organic Search, Lead Source - Other, Lead Source - Reference, Lead Source - Referral Sites, Lead Source - Welingak Website, Country - India, Country - Other, Specialization - Banking, Investment And Insurance, Specialization - Business Administration, Specialization - E-Business, Specialization - E-COMMERCE, Specialization - Finance Management, Specialization - Healthcare Management, Specialization - Hospitality Management, Specialization - Human Resource Management, Specialization - IT Projects Management, Specialization - International Business, Specialization - Marketing Management, Specialization - Media and Advertising, Specialization - Operations Management, Specialization - Others, Specialization - Retail Management, Specialization - Rural and Agribusiness, Specialization - Services Excellence, Specialization - Supply Chain Management, Specialization - Travel and Tourism, What is your current occupation - Businessman, What is your current occupation - Housewife, What is your current occupation - Other, What is your current occupation - Student, What is your current occupation - Unemployed, What is your current occupation - Working Professional, What matters most to you in choosing a course - Better Career Prospects, What matters most to you in choosing a course - Flexibility & Convenience, What matters most to you in choosing a course - Other, Lead Profile - Dual Specialization Student, Lead Profile - Lateral Student, Lead Profile - Other Leads, Lead Profile - Potential Lead, Lead Profile - Student of SomeSchool, Last Notable Activity - Approached upfront, Last Notable Activity - Email Bounced, Last Notable Activity - Email Link Clicked, Last Notable Activity - Email Marked Spam, Last Notable Activity - Email Opened, Last Notable Activity - Email Received, Last Notable Activity - Form Submitted on Website, Last Notable Activity - Had a Phone Conversation, Last Notable Activity - Modified, Last Notable Activity - Olark Chat Conversation, Last Notable Activity - Page Visited on Website, Last Notable Activity - Resubscribed to emails, Last Notable Activity - SMS Sent, Last Notable Activity - Unreachable, Last Notable Activity - Unsubscribed, Last Notable Activity - View in browser link Clicked]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 86 columns]\n"
     ]
    }
   ],
   "source": [
    "if IS_TEST_MODE:\n",
    "    print(drop_df.shape)\n",
    "    dddf = step_2_pipline(step_1_pipline(get_data()))\n",
    "    print(dddf.shape)\n",
    "    df_ohe = one_hot_featuers(drop_df)\n",
    "    print(df_ohe.shape)\n",
    "    print(one_hot_featuers(dddf).shape)\n",
    "    print(df_ohe[df_ohe.isnull().any(axis=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0    7946\n",
      "3.0     903\n",
      "1.0     391\n",
      "Name: Asymmetrique Activity Index, dtype: int64\n",
      "14.0    5878\n",
      "15.0    1293\n",
      "13.0     775\n",
      "16.0     549\n",
      "17.0     349\n",
      "12.0     225\n",
      "11.0      95\n",
      "10.0      57\n",
      "9.0        9\n",
      "18.0       5\n",
      "8.0        4\n",
      "7.0        1\n",
      "Name: Asymmetrique Activity Score, dtype: int64\n",
      "2.0    5944\n",
      "3.0    3265\n",
      "1.0      31\n",
      "Name: Asymmetrique Profile Index, dtype: int64\n",
      "15.0    4915\n",
      "18.0    2133\n",
      "16.0     599\n",
      "17.0     579\n",
      "20.0     308\n",
      "19.0     245\n",
      "14.0     226\n",
      "13.0     204\n",
      "12.0      22\n",
      "11.0       9\n",
      "Name: Asymmetrique Profile Score, dtype: int64\n",
      "(9240, 86)\n"
     ]
    }
   ],
   "source": [
    "if IS_TEST_MODE:\n",
    "    imp_df = data_imputer_on_asymmetrique_features(df_ohe)\n",
    "    print(imp_df[\"Asymmetrique Activity Index\"].value_counts(dropna = False))\n",
    "    print(imp_df[\"Asymmetrique Activity Score\"].value_counts(dropna = False))\n",
    "    print(imp_df[\"Asymmetrique Profile Index\"].value_counts(dropna = False))\n",
    "    print(imp_df[\"Asymmetrique Profile Score\"].value_counts(dropna = False))\n",
    "    print(imp_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0  :  14.0\n",
      "3.0  :  16.0\n",
      "1.0  :  12.0\n",
      "---------\n",
      "2.0  :  15.0\n",
      "3.0  :  18.0\n",
      "1.0  :  12.0\n"
     ]
    }
   ],
   "source": [
    "if IS_TEST_MODE:\n",
    "    for ac_index in imp_df[\"Asymmetrique Activity Index\"].unique():\n",
    "         print(ac_index,\" : \",df_ohe.loc[(imp_df[\"Asymmetrique Activity Index\"] == ac_index) & (df_ohe[\"Asymmetrique Activity Score\"] != nan_replacment)][\"Asymmetrique Activity Score\"].median())\n",
    "    print(\"---------\")\n",
    "    for ac_index in imp_df[\"Asymmetrique Profile Index\"].unique():\n",
    "         print(ac_index,\" : \",df_ohe.loc[(imp_df[\"Asymmetrique Profile Index\"] == ac_index) & (df_ohe[\"Asymmetrique Profile Score\"] != nan_replacment)][\"Asymmetrique Profile Score\"].median())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}